---
layout: post
title: Chapter 03. 스파크 설치하기
comments: true
categories: [Intro to Apache Spark]
tags: [Spark]
author: lsjhome
---

# Chapter 03 스파크 설치하기

## 3.1 이 책의 스파크 작동 환경

### 3.1.1 머신 구성

| 호스트명     | 역할        | 설명                                                         |
| ------------ | ----------- | ------------------------------------------------------------ |
| spark-client | 클라이언트  | 애플리케이션을 구동하는 클라이언트<br />단일 환경에서는 이 호스트만을 사용 |
| spark-master | 마스터 노드 | 클러스터 내의 리소스를 집중 관리                             |

단일 머신으로 스파크의 작동 환경을 설치하는 경우는 spark-cleint 만을 이용한다. 단일 머신 환경에서는 스파크의 데이터소스로서 주로 로컬 파일시스템을 이용한다.

클러스터 환경에서는 하둡의 클러스터 관리 시스템인 YARN을 이용하고, 스파크 데이터 소스로는 주로 분산 파일시스템인 HDFS를 이용한다. 이 HDFS와 YARN은 spark-master와 spark-worker00 ~ spark-worker03에 설치한다.

HDFS에의 파일 전송과 참조, 저장은 spark-client를 이용한다.

### 3.1.2 스파크 패키지

## 3.2 스파크 설치(단일 머신/클러스터 공통)

### 3.2.1 OS 설치

책에서는 64비트용 CentOS 6버전을 사용한다.

### 3.2.2 JDK 설치

Oracle JDK8을 이용한다.

```
$ java -version
java version "<JDK 버전>"
...
```

### 3.2.3 스파크 설치

https://spark.apache.org/downloads.html 에서 원하는 Spark를 설치하고 ```SPARK_HOME```을 export 해 준다. 

```
$ spark-submit --version
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0
      /_/

Using Scala version 2.11.12, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_202
Branch
Compiled by user  on 2018-10-29T06:22:05Z
Revision
Url
Type --help for more information.
```

샘플 프로그램 실행

```
$ spark-submit --class org.apache.spark.examples.SparkPi ${SPARK_HOME}/examples/jars/spark-examples_2.11-2.4.0.jar 10

...
Pi is roughly 3.1426511426511428
...
```

## 3.3 스파크 설치(클러스터용 추가 작업)

HDFS와 YARN을 설치하고, 클라이언트 노드에 대해서도 HDFS와 YARN을 이용 가능하게 한다.

### 3.3.1 HDFS란 무엇인가?

HDFS는 하둡 분산 파일 시스템으로, 클러스터 환경에서의 작동을 전제로 설계되었다.

NameNode라고 하는 마스터 노드와 DataNode라고 하는 복수의 워커 노드로 구성된다.

- NameNode
  HDFS의 마스터 노드에 해당한다. HDFS상에 보존되는 파일의 메다데이터와 보존된 파일의 분한될 조각(블록)이 어떤 DataNode에서 관리되는지 등의 정보를 관리한다.
- DataNode
  HDFS의 워커 노드를 뜻한다. HDFS상에 보존된 파일의 블록을 관리한다.

HDFS는 파일을 블록 단위로 분할하고, 각 블록을 복수의 DataNode에 분산해 저장함으로써 수 기가바이트에서 수 페타바이트에 달하는 거대한 데이터를 보존할 수 있다. 또한 일반적인 파일시스템과 비교해 기본 블록 크기가 128MB로 커서, 거대한 파일을 다룰 때 높은 I/O 처리량을 실현할 수 있다.

HDFS는 슬레이브 노드인 DataNode를 추가함으로써 I/O 처리량과 저장 용량을 스케일아웃 할 수 있다. 또 블록을 기본 3개의 DataNode에 레플리카하여 보존함으로써, 일부 슬레이브 노드가 고장을 일으키더라도 데이터 손실이 없도록 설계되었다.

### 3.3.2 YARN이란 무엇인가?

YARN은 하둡의 클러스터 관리 시스템으로, 스파크를 비롯한 각종 분산처리 프레임워크로 개발한 애플리케이션이 작동하는 환경을 제공/관리하는 기반이다. YARN은 Resource Manager라고 불리는 마스터노드와 NodeManager라고 하는 여러 개의 워커 노드로 구성된다.

- ResourceManager
  클러스터 전체의 계산 리소스를 관리하고, 클라이언트가 요구한 리소스를 NodeManager로부터 확보하도록 스케줄링한다. 요청된 이그제큐터 개수와 CPU 코어의 수, 메모리 야에 따라 이그제큐터를 하나 이상의 NodeManager로부터 확보하는 역할을 담당한다.
- NodeManager
  클러스터 전체의 계산 리소스를 관리하는 ResourceManager와는 달리, 자신이 설치된 머신(노드)의 계산 리소스만을 관리한다. ResourceManager로부터 받은 요청에 따라, 필요한 계산 리소스를 확보한 '컨테이너'라는 애플리케이션의 실행 환경을 제공한다. 요청된 컨테이너의 개수에 따라서 복수의 NodeManager로부터 컨테이너를 확보해 분산 처리한다. 

### 3.3.3 이 책에서의 HDFS와 YARN의 구성

데이터 지역성을 살리고자 보통 DataNode와 NodeManager는 같은 머신에 설치한다.

> 데이터 지역성이란 처리에 필요한 데이터와 처리를 실행하는 프로세스가 물리적으로 같은 머신에 존재하는 것을 뜻한다.

spark-worker00 ~ spark-worker03에 DataNode와 NodeManager를 설치한다. spark-master에 NameNode와 ResourceManager를 둘다 설치한다. spark-client에는 HDFS상의 파일에 접근하거나 HDFS와 YARN의 상태를 확인하기 위해 클라이언트용 컴포넌트를 설치한다.

### 3.3.4 CDH용 Yum 리포지터리 등록

### 3.3.5 마스터 노드 설치

NameNode부터 시작한다.

~~~shell
$ sudo yum install -y hadoop-hdfs-namenode
~~~

ResourceManager를 설치한다.

```
$ sudo yum install -y hadoop-yarn-resourcemanager
```

### 3.3.6 워커 노드 설치

DataNode를 설치

```
$ sudo yum install -y hadoop-hdfs-datanode
```

계속해서 NodeManager를 설치

```
$ sudo yum install -y hadoop-yarn-nodemanager
```

### 3.3.7 클라이언트 설치

spark-client에 HDFS와 YARN을 다루는 컴포넌트를 설치한다.

```
$ sudo yum install -y hadoop-hdfs hadoop-yarn
```

```${SPARK_HOME}/conf```에 spark-env.sh를 root 권한으로 작성하고 HDFS를 이용하도록 HADOOP_CONF_DIR 변수를 설정한다.

```
HADOOP_CONF_DIR=/etc/hadoop/conf
```

### 3.3.8 HDFS와 YARN의 환경 설정과 동작 확인

```/etc/hadoop/conf``` 에 있는 ```core-site.xml``` ```hdfs-site.xml``` ```yarn-site.xml``` 을 각각 root 권한으로 편집한다.