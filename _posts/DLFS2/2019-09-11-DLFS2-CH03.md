---
layout: post
title: Chapter 03. word2vec
comments: true
categories: [Deep Learning from Scratch 2]
tags: [Deep Learning, Machine Learning]
author: lsjhome

---

# Chapter 03 word2vec

앞 장에서는 '통계 기반 기법'으로 단어의 분산 표현을 얻었는데, 이번 장에서는 더 강력한 기법인 '추론 기반 기법'을 살펴보자.

'단순한' word2vec을 구현하자. 처리 효율을 희생하는 대신 이해하기 쉽도록 구성해서 '단순한' word2vec이다. 큰 데이터셋은 어려워도 작은 데이터셋이라면 문제없이 처리 가능하다.

## 3.1 추론 기반 기법과 신경망

단어를 벡터로 표현하는 방법으로는 '통계 기반 기법'과 '추론 기반 기법'이 있다. 단어의 의미를 얻는 방식은 서로 크게 다르지만, 그 배경에는 모두 분포 가설이 있다.

이번 절에서는 통계 기반 기법의 문제를 지적하고, 그 대안인 추론 기반 기법의 이점을 거시적 관점에서 설명한다. 그런 다음 word2vec의 전처리를 위해 신경망으로 '단어'를 처리하는 예를 보자.

### 3.1.1 통계 기반 기법의 문제점

통계 기반 기법에서는 주변 단어의 빈도를 기초로 단어를 표현했다.  구체적으로는 단어의 동시발생 행렬을 만들고 그 행렬에 SVD를 적용하여 밀집벡터 (단어의 분산 표현)을 얻었다.  

현업에서 다루는 말뭉치의 어휘 수는 어마어마하다. 예컨대 영어의 어휘 수는 100만을 훌쩍 넘고, 어휘가 100만 개라면, 통계 기반 기법에서는 '100만 X 100만'이라는 거대한 행렬을 만들게 된다. 이러한 거대 행렬에 SVD를 적용하는 것은 현실적이지 않다.

> SVD를 $$n \times n $$ 행렬에 적용하는 비용은 $$O(n^{3})$$ 이다. 계산 시간이 n의 3 제곱에 비례한다는 뜻이다. 실제로는 근사적인 기법과 희소행렬의 성질 등을 이용해 속도를 개선할 수 있지만, 그렇다고 해도 여전히 상당한 컴퓨팅 자원을 들여 장시간 계산해야 한다.

통계 기반 기법은 말뭉치 전체의 통계(동시발생 행렬과 PPMI 등)을 이용해 단 1회의 처리만에 단어의 분산 표현을 얻는다. 한편, 추론 기반 기법에서는, 예컨데 신경망을 이용하는 경우는 미니배치로 학습하는 것이 일반적이다. 미니배치 학습에서는 신경망이 한번에 소량(미니배치)의 학습 샘플씩 반복해서 학습하며 가중치를 갱신해 나간다.

![fig 3-1](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-1.png)

통계 기반 기법은 학습 데이터를 한꺼번에 처리한다(배치 학습). 이에 반해 추론 기반 기법은 학습 데이터의 일부를 사용하여 순차적으로 학습한다(미니배치 학습). 이 말은 말뭉치의 어휘 수가 많아 SVD등 계산량이 큰 작업을 처리하기 어려운 경우에도 신경망을 학습할 수 있다는 뜻이다. 데이터를 작게 나눠 학습하기 때문이다. 게다가 여러 머신과 여러 GPU를 이용한 병령 계산도 가능해져서 학습 속도를 높일 수 있다. 추론 기반 기법이 큰 힘을 발휘하는 영역이다.

## 3.1.2 추론 기반 기법 개요

추론 기반 기법에서는 당연히 '추론'이 주된 작업이다. 추론이란 아래 그림처럼 주변 단어(맥락)이 주어졌을 때 "?"에 무슨 단어가 들어가는지를 추측하는 작업이다.

![fig 3-2](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-2.png)

[그림 3-2]처럼 추론 문제를 풀고 학습하는 것이 '추론 기반 기법'이 다루는 문제이다. 이러한 추론 문제를 반복해서 풀면서 단어의 출연 패턴을 학습하는 것이다. '모델 관점'에서 보면, 이 문제는 아래 그림처럼 보인다.

![fig 3-3](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-3.png)

추론 기반 기법에는 어떠한 모델이 등장한다. 우리는 이 모델로 신경망을 사용한다. 모델은 맥락 정보를 입력받아 (출현할 수 있는) 각 단어의 출현 확률을 출력한다. 이러한 틀 안에서 말뭉치를 사용해 모델이 올바른 추측을 내놓도록 학습시킨다. 그리고 그 학습의 결과로 단어의 분산 표현을 얻는 것이 추론 기반 기법의 전체 그림이다.

### 3.1.3 신경망에서의 단어 처리

지금부터 신경망을 이용해 '단어'를 처리한다. 그런데 신경망은 "you"와 "say"등의 단어를 있는 그대로 처리할 수 없으니 단어를 '고정 길이의 벡터'로 변환해야 한다. 원핫 표현이란 벡터의 원소 중 하나만 1이고 나머지는 모두 0인 벡터를 말한다.

"You say goodbye and I say hello." 에서는 어휘가 총 7개 등장한다.

![fig 3-4](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-4.png)

단어는 텍스트, 단어ID, 그리고 원핫 표현 형태로 나타낼 수 있다. 단어를 고정 길이 벡터로 변환하면 우리 신경망의 입력층은 뉴런의 수를 '고정'할 수 있다.

![fig 3-5](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-5.png)

입력층의 뉴런은 총 7개이다. 이 7개의 뉴런은 차례로 7개의 단어들에 대응한다. 아래의 그림은 원핫 표현으로 된 단어 하나를 완전연결계층을 통해 변환하는 모습을 보여준다.

![fig 3-6](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-6.png)

위의 신경망은 완전연결계층이므로 각각의 노드가 이웃 층의 모든 노드와 화살표로 연결되어 있다. 이 화살표에는 가중치(매개변수)가 존재하며, 입력층 뉴런과의 가중합(weighted sum)이 은닉층 뉴런이 된다. 참고로 편향은 생략했다.

> 편향을 이용하지 않은 완전연결계층은 '행렬 곱' 계산에 해당된다. 그래서 이 책의 경우, 완전연결계층은 1장에서 구현한 MatMul 계층과 같아진다. 참고로 딥러닝 프레임워크들은 일반적으로 완전연결계층을 생성할 때 편향을 이용할지 선택할 수 있도록 해준다.

![fig 3-7](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-7.png)

이를 파이썬으로 작성해 보자

```python
import numpy as np

c = np.array([[1, 0, 0, 0, 0, 0, 0,]]) # 입력
W = np.random.randn( 7, 3) # 가중치
h = np.matmul(c, W)
>>> print (h)
[[0.88249023 1.19435831 0.35968298]]
```

이 코드는 단어 ID가 0인 단어를 원핫 표현으로 표현한 다음 완전연결계층을 통과시켜 변환하는 모습을 보여준다. 복습해보자면, 완전연결계층의 계산은 행렬 곱으로 수행할 수 있고, 행렬 곱은 넘파이의 np.matmul()이 해결해 준다. (편향은 생략)

> 입력 데이터(c)는 2차원(ndim)이다. 이는 미니배치 처리를 고려한 것으로, 최초의 차원(0번째 차원)에 각 데이터를 저장한다.

앞의 코드에서 주목할 곳은 c와 W의 행렬 곱 부분이다. c는 원핫 표현이므로 단어 ID에 대응하는 원소만 1이고 그 외에는 0인 벡터이다. 따라서 앞 코드의 c와 W의 행렬 곱은 결국 아래 그림처럼 가중치의 행벡터 하나를 '뽑아낸' 것과 같다.

![fig 3-8](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-8.png)

그저 가중치로부터 행벡터를 뽑아낼 뿐인데 행렬 곱을 계산하는 건 비효율적이다. 이 부분은 나중에 4장에서 개선한다. 또한 앞의 코드는 1장에서 구현한 MatMul 계층으로도 수행할 수 있다.

```python
import sys
sys.path.append('..')
import numpy as np
from common.layers import MatMul

c = np.array([1, 0, 0, 0, 0, 0, 0])
W = np.random.randn(7, 3)
layer = MatMul(W)
h = layer.forward(c)
>>> print (h)
[-0.82113105 -0.11894223  2.47562252]
```

common 디렉터리에 있는 MatMul 계층을 임포트하여 사용한다. 그런 다음 MatMul 계층에 가중치 W를 설정하고 forward() 메서드를 호출해 순전파를 수행한다.

## 3.2 단순한 word2vec

> CBOW 모델과 skip-gram 모델은 word2v2c에서 사용되는 신경망이다.

### 3.2.1 CBOW 모델의 추론 처리

CBOW 모델은 맥락으로부터 타깃(target)을 추측하는 용도의 신경망이다. 우리는 이 CBOW 모델이 가능한 한 정확하게 추론하도록 훈련시켜서 단어의 분산 표현을 얻어낼 것이다. 

CBOW 모델의 입력은 맥락이다. 맥락은 "you"와 "goodbye" 같은 단어들의 목록이다. 가장 먼저, 이 맥락을 원핫 표현으로 변환하여 **CBOW** 모델이 처리할 수 있도록 준비한다. 

![fig 3-9](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-9.png)

위 그림이 CBOW모델의 신경망이다. 입력층이 2개 있고, 은닉층을 거쳐 출력층에 도달한다. 두 입력층에서 은닉층으로의 변환은 똑같은 완전연결계층(가중치는 $$W_{in}$$)이 처리한다. 그리고 은닉층에서 출력층 뉴런으로의 변환은 다른 완전연결계층 (가중치는 $$W_{out}$$)이 처리한다.

> 입력층이 2개인 이유는, 맥락으로 고려할 단어를 2개로 정했기 때문이다. 즉 맥락에 포함시킬 단어가 N개라면 입력층도 N개가 된다.

은닉층의 뉴런은 입력층의 완전연결계층에 의해 변환된 값이 되는데, 입력층이 여러 개이면 전체를 '평균'하면 된다. 앞의 예에 대입해보면 다음과 같다.

완전연결계층에 의한 첫 번째 입력층이 $$h_{1}$$ 으로 변환되고, 두 번째 입력층이 $$h_{2}$$ 로 변환되었다고 하면, 은닉층 뉴런은 $$ \frac{1}{2}(h_{1} + {h_{2}}) $$ 가 된다.

마지막으로 [그림 3-9]의 출력층을 보자. 출력층의 뉴런은 7개인데, 여기서 중요한 것은 이 뉴런 하나하나가 각각의 단어에 대응한다는 점이다. 그리고 출력층 뉴런은 각 단어의 '점수'를 뜻하며, 값이 높을수록 대응 단어의 출현 확률도 높아진다. 여기서 점수란 확률로 해석되기 전의 값이고, 이 점수에 소프트맥스 함수를 적용해서 '확률'을 얻을 수 있다.

> 점수를 Softmax 계층에 통과시킨 후의 뉴런을 '출력층'이라고도 한다. 이 책에서는 점수를 출력하는 노드를 '출력층'이라고 한다.

입력층에서 은닉층으로의 변환은 완전연결계층 $$W_{in}$$에 의해서 이뤄진다. 이때 완전연결계층의 가중치 행렬 $$W_{in}$$은 $$ 7 \times 3$$ 행렬이며, 이 가중치가 바로 단어의 분산 표현의 정체이다. 아래와 같다.

![fig 3-10](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-10.png)

위에서 보듯 가중치 $$W_{in}$$의 각 행에는 해당 단어의 분산 표현이 담겨 있다고 볼 수 있다. 따라서 학습을 진행할수록 맥락에서 출현하는 단어를 잘 추측하는 방향으로 이 분산 표현들이 갱신될 것이다. 그리고 놀랍게도 이렇게 해서 얻은 벡터에는 '단어의 의미'도 잘 녹아들어 있다. 이것이 word2v2c의 전체 그림이다. 

> 은닉층의 뉴런 수를 입력층의 뉴런 수보다 적게 하는 것이 중요한 핵심이다. 이렇게 해야 은닉층에는 단어 예측에 필요한 정보를 '간결하게' 담게 되며, 결과적으로 밀집벡터 표현을 얻을 수 있다. 이때 그 은닉층의 정보는 우리 인간은 이해할 수 없는 코드로 쓰여 있다. 바로 '인코딩'에 해당한다. 한편 은닉층의 정보로부터 원하는 결과를 얻는 작업은 '디코딩'이라고 한다. 즉 디코딩이란 인코딩된 정보를 우리 인간이 이해할 수 있는 표현으로 복원하는 작업이다.

'계층 관점'에서는 아래와 같다.

![fig 3-11](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-11.png)

CBOW 모델의 추론 처리를 파이썬으로 구현해보자. (추론 처리란 '점수'를 구하는 처리를 말한다.) 이는 다음과 같이 구현할 수 있다.

```python
import sys
sys.path.append('..')
import numpy as np
from common.layers import MatMul

# 샘플 맥락 데이터
c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])
c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])

# 가중치 초기화
W_in = np.random.randn(7, 3)
W_out = np.random.randn(3, 7)

# 계층 생성
in_layer0 = MatMul(W_in)
in_layer1 = MatMul(W_in)
out_layer = MatMul(W_out)

# 순전파
h0 = in_layer0.forward(c0)
h1 = in_layer0.forward(c1)
h = 0.5 * (h0 + h1)
s = out_layer.forward(h)

>>> print(s)
[[-0.81878343  1.26872819 -0.71840636 -0.95922586  3.37397072  0.39420103
   0.96151233]]
```

가장 먼저, 필요한 가중치들(W\_in과 W\_out)을 초기화 한다. 그리고 입력층을 처리하는 MatMul 계층을 맥락 수만큼(여기서는 2개) 생성하고, 출력층 측의 MatMul 계층은 1개만 생성한다. 이때 입력층 측의 MatMul 계층은 W\_in을 공유한다는 점에 주의하자.

다음은 입력층 측의 MatMul 계층들 (in\_layer0과 in\_layer1)의 forward() 메서드를 호출해 중간 데이터를 계산하고, 출력층 측의 MatMul 계층을 통과시켜 각 단어의 점수를 구한다.

### 3.2.2 CBOW 모델의 학습

지금까지 설명한 CBOW 모델은 출력층에서 각 단어의 점수를 출력했다. 이 점수에 소프트맥스 함수를 적용하면 '확률'을 얻을 수 있는데, 이 확률은 맥락(전후 단어)가 주어졌을 때 그 중앙에 어떤 단어가 출현하는지를 나타낸다.

아래 그림에서 맥락은 "you"와 "goodbye"이고, 정답 레이블은 "say"이다. 이때 '가중치가 적절히 설정된' 신경망이라면 '확률'을 나타내는 뉴런들 중 정답에 해당하는 뉴런의 값이 클 것이라 기대할 수 있다.

![fig 3-12](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-12.png)

CBOW 모델의 학습치에는 올바른 예측을 할 수 있도록 가중치를 조정하는 일을 한다. 그 결과로 $$W_{in}$$에 단어의 출현 패턴을 파악한 벡터가 학습된다. 그리고 CBOW 모델로 얻을 수 있는 단어의 분산 표현은 단어의 의미 면에서나 문법 면에서 모두 우리의 직관에 부합하는 경우를 많이 볼 수 있다. 

> CBOW모델은 단어 출현 패턴을 학습 시 사용한 말뭉치로부터 배운다. 따라서 말뭉치가 다르면 학습 후 얻게 되는 단어의 분산 표현도 달라진다. 예컨데 말뭉치로 '스포츠' 기사만을 사용하는 경우와 '음악'관련 기사만을 사용하는 경우는 얻게 되는 단어의 분산 표현이 크게 다를 것이다.

이 모델은 다중 클래스 분류를 수행하는 신경망이다. 따라서 소프트맥스 함수를 이용해 점수를 확률로 변환하고, 그 확률과 정답 레이블로부터 교차 엔트로피 오차를 구한 후, 그 값을 손실로 사용해 학습을 진행한다.

![fig 3-13](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-13.png)

그림에서 보듯, 앞 절에서 설명한 추론 처리를 수행하는 CBOW 모델에 Softmax 계층과 Cross Entropy Error 계층을 추가했을 뿐이다. 이것만으로 손실을 얻을 수 있다. 이상이 CBOW 모델의 손실을 구하는 계산의 흐름이다.

두 계층을 Softmax with Loss라는 하나의 계층으로 구현하면 그림은 아래와 같이 된다.

![fig 3-14](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-14.png)

### 3.2.3 word2vec의 가중치와 분산 표현

word2vec에서 사용되는 신경망에는 두 가지 가중치가 있다. 바로 입력 측 완전연결계층의 가중치($$W_{in}$$)와 출력 측 완전연결계층의 가중치 ($$W_{out}$$)이다. 그리고 입력 측 가중치 $$W_{in}$$의 각 행이 각 단어의 분산 표현에 해당한다. 또한 출력 측 가중치 $$W_{out}$$에도 단어의 의미가 인코딩된 벡터가 저장되어 있다고 생각할 수 있다. 다만, 출력 측 가중치는 아래 그림에서 보듯 각 단어의 분산 표현이 열 방향(수직 방향)으로 저장된다.

![fig 3-15](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-15.png)

최종적으로 이용하는 단어의 분산 표현으로는 어떤 쪽 가중치를 표현하는 것이 좋을까?

- A 입력 측의 가중치만 이용한다.
- B 출력 측의 가중치만 이용한다.
- C 양쪽 가중치를 모두 이용한다.

word2vec (특히 skip-gram 모델) 에서는 '입력 측의 가중치만 이용한다'가 가장 대중적인 선택이다. 많은 연구에서 출력 측 가중치는 버리고, 입력 측 가중치 $$W_{in}$$ 만을 최종 단어의 분산 표현으로써 이용한다.

## 3.3 학습 데이터 준비

"You say goodbye and I say Hello."라는 한 문장짜리 말뭉치를 이용한다.

### 3.3.1 맥락과 타깃

![fig 3-16](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-16.png)

목표로 하는 단어를 '타깃'으로, 그 주변 단어를 '맥락'으로 뽑아냈다. 각 샘플 데이터에서 맥락의 수는 여러 개(이 예에서는 2개)가 될 수 있으나, 타깃은 오직 하나뿐이다. 그래서 맥락을 영어로 쓸 때는 끝에 's'를 붙여 복수형임을 명시하는 것이 좋다.

말뭉치로부터 맥락과 타깃을 만드는 함수를 구현할 텐데, 그 전에 앞 장의 내용을 살짝 복습해 보자. 우선 말뭉치 텍스트를 단어 ID로 변환해야 한다. 이 작업에는 2장에서 구현한 preprocess() 함수를 사용한다.

```python
from common.util import preprocess

text = 'You say goodbye and I say hello.'

corpus, word_to_id, id_to_word = preprocess(text)
print (corpus)
# [0 1 2 3 4 1 5 6]
print (id_to_word)
# {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}
```

그런 다음 단어 ID의 배열인 corpus로부터 맥락과 타깃을 만들어낸다. 구체적으로는 아래 그림처럼 corpus를 주변 맥락과 타깃을 반환하는 함수를 작성한다.

![fig 3-17](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-17.png)

맥락은 2차원 배열이다. 이때 맥락의 0번째 차원에는 각 맥락 데이터가 저장된다. 

```python
def create_contexts_target(corpus, window_size=1):
    '''맥락과 타깃 생성

    :param corpus: 말뭉치(단어 ID 목록)
    :param window_size: 윈도우 크기(윈도우 크기가 1이면 타깃 단어 좌우 한 단어씩이 맥락에 포함)
    :return:
    '''
    target = corpus[window_size:-window_size]
    contexts = []

    for idx in range(window_size, len(corpus)-window_size):
        cs = []
        for t in range(-window_size, window_size + 1):
            if t == 0:
                continue
            cs.append(corpus[idx + t])
        contexts.append(cs)

    return np.array(contexts), np.array(target)
```

이 함수는 단어 ID의 배열(corpus), 윈도우 크기(window size)두개를 인수로 받는다. 그리고 맥락과 타깃을 각각 넘파이 배열로 돌려준다.

```python
contexts, target = create_contexts_target(corpus, window_size=1)

>>> print (contexts)
[[0 2]
 [1 3]
 [2 4]
 [3 1]
 [4 5]
 [1 6]]
>>> print (target)
[1 2 3 4 1 5]
```

맥락과 타깃이 있으니 이를 CBOW 모델에 넘겨주면 된다. 이 맥락과 타깃의 각 원소는 여전히 단어 ID이다. 이어서 이를 원핫 표현으로 변환해 보자.

### 3.2.2 원핫 표현으로 변환

계속해서 맥락과 타깃을 원핫 표현으로 바꿔 보자. 이때 수행하는 변환은 [그림 3-18]과 같다. 

![fig 3-18](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-18.png)

위 그림에서는 맥락과 타깃을 단어 ID에서 원핫 표현으로 변환하면 된다. 맥락의 형상은 (6, 2)에서 (6, 2, 7)이 된다.

```python
from common.util import preprocess, create_contexts_target, convert_one_hot

text = 'You say goodbye and I say hello.'
corpus, word_to_id, id_to_word = preprocess(text)

contexts, target = create_contexts_target(corpus, window_size=1)

vocab_size = len(word_to_id)
target = convert_one_hot(target, vocab_size)
contexts = convert_one_hot(contexts, vocab_size)
```

학습 데이터 준비가 되었다.

## 3.4 CBOW 모델 구현

우리가 구현할 모델은 아래와 같다.

![fig 3-19](/Users/jin/projects/lsjhome.github.io/assets/img/dlfs2/deep_learning_2_images/fig 3-19.png)

신경망을 SimpleCBOW라는 이름으로 구현해 보자.

```python
# coding: utf-8
import sys
sys.path.append('..')
import numpy as np
from common.layers import MatMul, SoftmaxWithLoss


class SimpleCBOW:
    def __init__(self, vocab_size, hidden_size):
        V, H = vocab_size, hidden_size

        # 가중치 초기화
        W_in = 0.01 * np.random.randn(V, H).astype('f')
        W_out = 0.01 * np.random.randn(H, V).astype('f')

        # 계층 생성
        self.in_layer0 = MatMul(W_in)
        self.in_layer1 = MatMul(W_in)
        self.out_layer = MatMul(W_out)
        self.loss_layer = SoftmaxWithLoss()

        # 모든 가중치와 기울기를 리스트에 모은다.
        # 하나에 모아 두면 옵티마이저 계산에서 for문만 돌리면 되니 편하다.
        # 옵티마이저에서 self.in_layer0.params의 값이 변하면 이것이 원소가 되는 self.params의 값도 변한다.
        layers = [self.in_layer0, self.in_layer1, self.out_layer]
        self.params, self.grads = [], []
        for layer in layers:
            self.params += layer.params
            self.grads += layer.grads

        # 인스턴스 변수에 단어의 분산 표현을 저장한다.
        self.word_vecs = W_in

    def forward(self, contexts, target):
        h0 = self.in_layer0.forward(contexts[:, 0])
        h1 = self.in_layer1.forward(contexts[:, 1])
        h = (h0 + h1) * 0.5
        score = self.out_layer.forward(h)
        loss = self.loss_layer.forward(score, target)
        return loss

    def backward(self, dout=1):
        ds = self.loss_layer.backward(dout)
        da = self.out_layer.backward(ds)
        da *= 0.5
        self.in_layer1.backward(da)
        self.in_layer0.backward(da)
        return None

```

초기화 메서드는 인수로 어휘 수(vocab\_size)와 은닉층의 뉴런 수(hidden\_size)를 받는다. 가중치 초기화 부분에서는 가중치를 2개 생성한다. (W\_in과 W\_out). 처음에는 둘다 작은 무작위 값으로 초기화 된다. 그리고 이때 넘파이 배열의 데이터 타입을 astype('f')로 지정한다. 즉, 32비트 부동소수점 수로 초기화한다.

이어서 필요한 계층을 생성한다. 입력 측의 MatMul 계층을 2개, 출력 측의 MatMul 계층을 하나, 그리고 Softmax with Loss 계층을 하나 생성한다. 

입력 측의 맥락을 처리하는 MatMul 계층은 맥락에서 단어의 수(윈도우 크기)만큼 만들어야 한다. 그래서 여기서는 단어의 양 옆인 2개를 만들었다. 그리고 **입력 측 MatMul 계층들은 모두 같은 가중치**를 이용하도록 초기화한다.

마지막으로 이 신경망에서 사용되는 매개변수와 기울기를 인스턴스 변수인 params와 grads 리스트에 각각 모아둔다.

> 이 코드에서는 여러 계층에서 같은 가중치를 공유하고 있다. 따라서 params 리스트에는 같은 가중치가 여러개 존재하게 된다. 